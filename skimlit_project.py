# -*- coding: utf-8 -*-
"""Skimlit_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IklWp9DE6qlDUNw1ov5jqn9zZg2zbnLt
"""

!nvidia-smi -L

!git clone https://github.com/Franck-Dernoncourt/pubmed-rct
!ls pubmed-rct

!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/

data_dir = "/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"

import os
filename = [data_dir + filename for filename in os.listdir(data_dir)]
filename

def get_lines(filename):
  with open(filename,"r") as f:
    return f.readlines()

train_lines = get_lines(data_dir + "train.txt")
train_lines[:10]

def preprocess_text_with_line_numbers(filename):

  input_lines = get_lines(filename)
  abstract_lines = ""
  abstract_samples = []


  for line in input_lines:
    if line.startswith("###"):
      abstract_id = line
      abstract_lines = ""
    elif line.isspace():
      abstract_line_split = abstract_lines.splitlines()


      for abstract_line_number, abstract_line in enumerate(abstract_line_split):
        line_data = {}
        target_text_split = abstract_line.split("\t")
        line_data["target"] = target_text_split[0]
        line_data["text"] = target_text_split[1].lower()
        line_data["line_number"] = abstract_line_number
        line_data["total_lines"] = len(abstract_line_split) - 1
        abstract_samples.append(line_data)

    else:
      abstract_lines += line

  return abstract_samples

train_samples = preprocess_text_with_line_numbers(data_dir + "train.txt")
val_samples = preprocess_text_with_line_numbers(data_dir + "dev.txt") # dev is another name for validation set
test_samples = preprocess_text_with_line_numbers(data_dir + "test.txt")
len(train_samples), len(val_samples), len(test_samples)

train_samples[:10]

train_sentences = train_df["text"].tolist()
val_sentences = val_df["text"].tolist()
test_sentences = test_df["text"].tolist()

import pandas as pd
train_df = pd.DataFrame(train_samples)
val_df = pd.DataFrame(val_samples)
test_df = pd.DataFrame(test_samples)

train_df

from sklearn.preprocessing import OneHotEncoder

onh = OneHotEncoder(sparse=False)
train_labels = onh.fit_transform(train_df['target'].to_numpy().reshape(-1,1))
val_labels = onh.fit_transform(val_df['target'].to_numpy().reshape(-1,1))
test_labels = onh.fit_transform(test_df['target'].to_numpy().reshape(-1,1))
train_labels

import tensorflow as tf
tf.constant(train_labels)

from sklearn.preprocessing import LabelEncoder
Le = LabelEncoder()
train_label_encoder = Le.fit_transform(train_df['target'].to_numpy())
val_label_encode = Le.fit_transform(val_df['target'].to_numpy())
test_label_encode = Le.fit_transform(test_df['target'].to_numpy())

"""Base line model

TF-IDF Multinomial Native Bayes classifier
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline

model_0 = Pipeline([
    ("tf-idf" , TfidfVectorizer()),
    ("clf" , MultinomialNB())
])

model_0.fit(X = train_sentences,
            y =train_label_encoder)

model_0.score(X=val_sentences,
                 y=val_label_encode)

baseline_preds = model_0.predict(val_sentences)
baseline_preds

from sklearn.metrics import accuracy_score,precision_recall_fscore_support
def calculate_result(y_true,y_pred):
    model_accuracy = accuracy_score(y_true,y_pred)*100
    model_precision, model_recall, model_f1,_ = precision_recall_fscore_support(y_true,y_pred,average="weighted")
    model_result = {"accuracy":model_accuracy,
                    "precision":model_precision,
                    "recall":model_recall,
                    "f1":model_f1}
    return model_result

calculate_result(y_true=val_label_encode,y_pred=baseline_preds)

